{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Refining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries for modeling and analysis \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction import stop_words\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in my first reddits file, without authors\n",
    "reddits = pd.read_csv('./data/reddits_preprocessed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>type</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>1553281124</td>\n",
       "      <td>she didnt mention this when i asked her  she...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>1553280963</td>\n",
       "      <td>i mean i was but not for the sole purpose of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>1553280896</td>\n",
       "      <td>hardly the best talent around in podcast has...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>1553280716</td>\n",
       "      <td>she cant do season 2 because gimlet owns the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>comment</td>\n",
       "      <td>1553280571</td>\n",
       "      <td>search party really excellent and critically...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit     type  created_utc  \\\n",
       "0          0  comment   1553281124   \n",
       "1          0  comment   1553280963   \n",
       "2          0  comment   1553280896   \n",
       "3          0  comment   1553280716   \n",
       "4          0  comment   1553280571   \n",
       "\n",
       "                                               words  \n",
       "0    she didnt mention this when i asked her  she...  \n",
       "1    i mean i was but not for the sole purpose of...  \n",
       "2    hardly the best talent around in podcast has...  \n",
       "3    she cant do season 2 because gimlet owns the...  \n",
       "4    search party really excellent and critically...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking out my dataframe \n",
    "reddits.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I tried this to see if my model improved by only including comments and not submissions, but it did not\n",
    "# make a significant difference, so I am commenting this out to show I tried\n",
    "# reddits = reddits[reddits['type'] == 'comment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting my X variable as the words, which will be the predictors, and y to be the predicted variable, \n",
    "# which is what subreddit a text is from \n",
    "X = reddits['words']\n",
    "y = reddits['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split with my data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=22, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Multinomial Naive Bayes was my best model, along with SVM. I am trying to see if I can change the alpha hyperparameter for any improvement. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=None,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=None,\n",
       "                                                        strip_accents=None,\n",
       "                                                        sublinear_tf=False,\n",
       "                                                        token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                                                        tokenizer=None,\n",
       "                                                        use_idf=True,\n",
       "                                                        vocabulary=None)),\n",
       "                                       ('nb',\n",
       "                                        MultinomialNB(alpha=1.0,\n",
       "                                                      class_prior=None,\n",
       "                                                      fit_prior=True))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'nb__alpha': [1, 0.1, 0.01]}, pre_dispatch='2*n_jobs',\n",
       "             refit=True, return_train_score=False, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Establishing the pipeline\n",
    "pipe = Pipeline([('tfidf', TfidfVectorizer()),\n",
    "                     ('nb', MultinomialNB())])\n",
    "# Setting my pipeline parameters\n",
    "pipe_params = {\n",
    "    'nb__alpha': [1, 1e-1, 1e-2],\n",
    "    \n",
    "}\n",
    "# Instantiating a grid search\n",
    "gs = GridSearchCV(pipe, \n",
    "                  param_grid=pipe_params) \n",
    "# Fitting my model\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7949924775962207"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The best score\n",
    "gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The best estimator, with an alpha of .01\n",
    "# gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the best estimator to the model\n",
    "gs_model = gs.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9158455899852445"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training score with alpha = .01\n",
    "gs_model.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8075110666857062"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing score with alpha = .01\n",
    "gs_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here I am trying fit_prior on my model as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7889474877414673"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a pipeline\n",
    "pipe2 = Pipeline([('tfidf', TfidfVectorizer(max_features=10000, \n",
    "                                           ngram_range=(1, 1), \n",
    "                                           stop_words=stop_words.ENGLISH_STOP_WORDS)),\n",
    "                     ('nb', MultinomialNB()),\n",
    "])\n",
    "# Setting my pipeline parameters \n",
    "pipe_params2 = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'nb__alpha': [.01],\n",
    "    'nb__fit_prior': [True, False],\n",
    "}\n",
    "# Instantiated a grid search\n",
    "gs2 = GridSearchCV(pipe2, \n",
    "                  param_grid=pipe_params2) \n",
    "# Fitting my model\n",
    "gs2.fit(X_train, y_train)\n",
    "# Checking my best score\n",
    "gs2.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting my best estimator to my model\n",
    "gs_model2 = gs2.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8715312485125423"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking my training score\n",
    "gs_model2.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7988005140654005"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking my testing score\n",
    "gs_model2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes Adding Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in my reddits data with authors included\n",
    "reddits2 = pd.read_csv('./data/reddits_preprocessed_authors.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning my new X and y variables\n",
    "X = reddits2['words']\n",
    "y = reddits2['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split on my new data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=22, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9082775785688705"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting my pipeline \n",
    "pipe3 = Pipeline([('tfidf', TfidfVectorizer(max_features=10000, \n",
    "                                           ngram_range=(1, 1), \n",
    "                                           stop_words=stop_words.ENGLISH_STOP_WORDS)),\n",
    "                     ('nb', MultinomialNB()),\n",
    "])\n",
    "# Setting my pipeline parameters \n",
    "pipe_params3 = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "    'nb__alpha': [0.01],\n",
    "    'nb__fit_prior': [True, False],\n",
    "}\n",
    "# Instantiating my grid search \n",
    "gs3 = GridSearchCV(pipe3, \n",
    "                  param_grid=pipe_params3) \n",
    "# Fitting my model\n",
    "gs3.fit(X_train, y_train)\n",
    "# Looking at my best score\n",
    "gs3.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model3 = gs3.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9541625017849493"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model3.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91360845351992"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model3.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = gs_model3.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred gimlet</th>\n",
       "      <th>pred maximum_fun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual gimlet</th>\n",
       "      <td>3127</td>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual maximum_fun</th>\n",
       "      <td>355</td>\n",
       "      <td>3271</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pred gimlet  pred maximum_fun\n",
       "actual gimlet              3127               250\n",
       "actual maximum_fun          355              3271"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df = pd.DataFrame(cm, columns=['pred gimlet', 'pred maximum_fun'], index=['actual gimlet', 'actual maximum_fun'])\n",
    "cm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model with Authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('tfidf',\n",
       "                                        TfidfVectorizer(analyzer='word',\n",
       "                                                        binary=False,\n",
       "                                                        decode_error='strict',\n",
       "                                                        dtype=<class 'numpy.float64'>,\n",
       "                                                        encoding='utf-8',\n",
       "                                                        input='content',\n",
       "                                                        lowercase=True,\n",
       "                                                        max_df=1.0,\n",
       "                                                        max_features=10000,\n",
       "                                                        min_df=1,\n",
       "                                                        ngram_range=(1, 1),\n",
       "                                                        norm='l2',\n",
       "                                                        preprocessor=None,\n",
       "                                                        smooth_idf=True,\n",
       "                                                        stop_words=frozenset(...\n",
       "                                            cache_size=200, class_weight=None,\n",
       "                                            coef0=0.0,\n",
       "                                            decision_function_shape='ovr',\n",
       "                                            degree=3, gamma='scale',\n",
       "                                            kernel='rbf', max_iter=-1,\n",
       "                                            probability=False,\n",
       "                                            random_state=None, shrinking=True,\n",
       "                                            tol=0.001, verbose=False))],\n",
       "                                verbose=False),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'tfidf__max_df': (0.25, 0.5, 0.75)},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=None, verbose=0)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the pipeline, this time just putting the features for TFIDF that have been most successful in the\n",
    "# pipeline rather than in the parameters. \n",
    "pipe4 = Pipeline([('tfidf', TfidfVectorizer(max_features=10000, \n",
    "                                           ngram_range=(1, 1), \n",
    "                                           stop_words=stop_words.ENGLISH_STOP_WORDS)),\n",
    "                     ('svc', SVC(gamma='scale')),\n",
    "])\n",
    "# Setting the parameters\n",
    "pipe_params4 = {\n",
    "    'tfidf__max_df': (0.25, 0.5, 0.75),\n",
    "}\n",
    "# Instantiating a grid search pipeline\n",
    "gs4 = GridSearchCV(pipe4, \n",
    "                  param_grid=pipe_params4) \n",
    "# Fitting the model\n",
    "gs4.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs_model4 = gs4.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9894806987481556"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model4.score(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9008996144509496"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs_model4.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions2 = gs_model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(y_test, predictions2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred gimlet</th>\n",
       "      <th>pred maximum_fun</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>actual gimlet</th>\n",
       "      <td>3102</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>actual maximum_fun</th>\n",
       "      <td>419</td>\n",
       "      <td>3207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    pred gimlet  pred maximum_fun\n",
       "actual gimlet              3102               275\n",
       "actual maximum_fun          419              3207"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cm_df2 = pd.DataFrame(cm2, columns=['pred gimlet', 'pred maximum_fun'], index=['actual gimlet', 'actual maximum_fun'])\n",
    "cm_df2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
