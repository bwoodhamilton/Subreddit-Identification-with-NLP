{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 3, NLP on Subreddits, Executive Summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the 1940s, when an Italian Jesuit Priest named Roberto Busa set out to analyze the works of Saint Thomas Aquinas, he had very little computing power and had to use more than 11 million punch cards to complete his decades-long project. These days we have so many different machine learning models at our fingertips, and it can be hard to narrow down the best one to use. As someone deeply interested in human language, I am fascinated by the different models that can classify text and voice and how they work. \n",
    "\n",
    "In this project, I gathered 28,000 submissions and comments from two subreddits for the podcast networks Maximum Fun and Gimlet. I chose these because the language would be similar enough for the models to be challenged, but different enough to be able to teach the machine to distinguish between them. I tried ten different classification models combined with two different word vectorizers to see which combination got the best result. Within those models, I set many different parameters in pipelines and grid searching to see which models performed the best, adding up to over 200 different models. \n",
    "\n",
    "Of the ten classification models I tried, the two that worked the best were Multinomial Naive Bayes and Support Vector Machine. While both got similar results in accuracy, the Multinomial Naive Bayes is quicker and more efficient. Of the two word vectorizors, in most models the TFIDF word vectorizer worked better than the count vectorizer, because the former gives words that are more unique to one category a higher rating, whereas the latter just uses word counts.\n",
    "\n",
    "Overall, the Multinomial Naive Bayes model with the TFIDF Vectorizer was about 90% accurate in identifying whether a reddit post was from Gimlet or Maximum Fun. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
